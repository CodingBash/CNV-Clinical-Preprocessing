{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning of Drug Response using CORES from Copy Number Log Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jul 26 12:21:38 2018\n",
    "\n",
    "@author: bbece\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from pprint import pprint\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "            \n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method to split training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manipulate test_ratio\n",
    "def split_train_test(training_set, test_ratio = 0.33):\n",
    "    row_count = training_set.shape[0]\n",
    "    shuffled_indices = np.random.permutation(row_count)\n",
    "    test_set_size = int(test_ratio * row_count)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return training_set.iloc[train_indices], training_set.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training set matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_matrix_training_set = pd.read_csv(\"../mlOutput/coreTrainingSet_7_26_2018_1.csv\")\n",
    "#labeled_matrix_training_set.columns.values[0] = \"sampleId\"\n",
    "labeled_matrix_training_set = labeled_matrix_training_set.drop([labeled_matrix_training_set.columns[0]], axis = 1)\n",
    "labels = list(range(0,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gemcitabine</th>\n",
       "      <th>Paclitaxel</th>\n",
       "      <th>SN-38</th>\n",
       "      <th>5-FU</th>\n",
       "      <th>Oxaliplatin</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576312</td>\n",
       "      <td>0.715357</td>\n",
       "      <td>0.542345</td>\n",
       "      <td>0.770327</td>\n",
       "      <td>0.875863</td>\n",
       "      <td>-0.023661</td>\n",
       "      <td>0.222033</td>\n",
       "      <td>-0.023462</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>-0.016246</td>\n",
       "      <td>-0.319758</td>\n",
       "      <td>-0.920562</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.351763</td>\n",
       "      <td>-0.017651</td>\n",
       "      <td>-0.924898</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>-0.023676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531357</td>\n",
       "      <td>0.481223</td>\n",
       "      <td>0.552329</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.802963</td>\n",
       "      <td>0.181613</td>\n",
       "      <td>0.487523</td>\n",
       "      <td>0.131467</td>\n",
       "      <td>0.232706</td>\n",
       "      <td>-0.335766</td>\n",
       "      <td>-0.370300</td>\n",
       "      <td>-1.097977</td>\n",
       "      <td>-0.051764</td>\n",
       "      <td>-0.398236</td>\n",
       "      <td>0.293325</td>\n",
       "      <td>-0.352274</td>\n",
       "      <td>-0.312039</td>\n",
       "      <td>0.157730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610292</td>\n",
       "      <td>0.748410</td>\n",
       "      <td>0.544124</td>\n",
       "      <td>0.673957</td>\n",
       "      <td>0.790218</td>\n",
       "      <td>-0.253551</td>\n",
       "      <td>0.778455</td>\n",
       "      <td>-0.144264</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>-0.853473</td>\n",
       "      <td>-1.758692</td>\n",
       "      <td>-0.177455</td>\n",
       "      <td>0.129708</td>\n",
       "      <td>-0.423099</td>\n",
       "      <td>-0.596137</td>\n",
       "      <td>0.224373</td>\n",
       "      <td>0.065391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677571</td>\n",
       "      <td>0.647227</td>\n",
       "      <td>0.562632</td>\n",
       "      <td>0.826889</td>\n",
       "      <td>0.835748</td>\n",
       "      <td>0.258173</td>\n",
       "      <td>0.257905</td>\n",
       "      <td>-0.721768</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>-0.788022</td>\n",
       "      <td>-0.644478</td>\n",
       "      <td>0.188872</td>\n",
       "      <td>-0.525897</td>\n",
       "      <td>-0.130485</td>\n",
       "      <td>-0.706107</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>-0.308589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.694529</td>\n",
       "      <td>0.653745</td>\n",
       "      <td>0.651769</td>\n",
       "      <td>0.850960</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>-0.004964</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>-0.081225</td>\n",
       "      <td>-0.876510</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-0.899463</td>\n",
       "      <td>0.098961</td>\n",
       "      <td>-0.060560</td>\n",
       "      <td>-0.007001</td>\n",
       "      <td>0.048844</td>\n",
       "      <td>-0.923308</td>\n",
       "      <td>-0.491210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gemcitabine  Paclitaxel     SN-38      5-FU  Oxaliplatin         2  \\\n",
       "0     0.576312    0.715357  0.542345  0.770327     0.875863 -0.023661   \n",
       "1     0.531357    0.481223  0.552329  0.778592     0.802963  0.181613   \n",
       "2     0.610292    0.748410  0.544124  0.673957     0.790218 -0.253551   \n",
       "3     0.677571    0.647227  0.562632  0.826889     0.835748  0.258173   \n",
       "4     0.694529    0.653745  0.651769  0.850960     0.813800  0.018108   \n",
       "\n",
       "          4         5         6         7         8         9        11  \\\n",
       "0  0.222033 -0.023462  0.005694 -0.016246 -0.319758 -0.920562  0.049898   \n",
       "1  0.487523  0.131467  0.232706 -0.335766 -0.370300 -1.097977 -0.051764   \n",
       "2  0.778455 -0.144264  0.021000  0.217868 -0.853473 -1.758692 -0.177455   \n",
       "3  0.257905 -0.721768  0.090314 -0.001879 -0.788022 -0.644478  0.188872   \n",
       "4 -0.004964 -0.018641 -0.081225 -0.876510 -0.943414 -0.899463  0.098961   \n",
       "\n",
       "         12        13        14        15        16  \n",
       "0  0.351763 -0.017651 -0.924898 -0.020597 -0.023676  \n",
       "1 -0.398236  0.293325 -0.352274 -0.312039  0.157730  \n",
       "2  0.129708 -0.423099 -0.596137  0.224373  0.065391  \n",
       "3 -0.525897 -0.130485 -0.706107 -0.079974 -0.308589  \n",
       "4 -0.060560 -0.007001  0.048844 -0.923308 -0.491210  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(labeled_matrix_training_set.copy().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize ML Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_training_set.head()\n",
    "#y = selected_training_set.copy()[[selected_training_set.columns[0]]]\n",
    "#X = selected_training_set.copy().drop([selected_training_set.columns[0]], axis=1)\n",
    "\n",
    "X = labeled_matrix_training_set.copy().drop(labeled_matrix_training_set.columns[labels], axis = 1)\n",
    "y = labeled_matrix_training_set.copy()[labeled_matrix_training_set.columns[labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# TODO: Using the above objects instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_pipelines(model_name, ml_model):\n",
    "    Ypipeline = Pipeline([\n",
    "     ('imputer', Imputer(axis=0,strategy=\"median\")),\n",
    "     ('standardizer', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    XYpipeline = Pipeline([\n",
    "            ('imputer', Imputer(axis=0,strategy=\"median\")),\n",
    "            ('standardizer', StandardScaler()),\n",
    "            (model_name,  ml_model)\n",
    "    ])\n",
    "    \n",
    "    return (Ypipeline, XYpipeline)\n",
    "\n",
    "def imputer_inverse_transform(pre_data, post_data):\n",
    "        na_indices = np.where(np.isnan(pre_data))[0]\n",
    "        pprint(na_indices)\n",
    "        post_data[na_indices] = float('NaN')\n",
    "        return post_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize ML results using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [56, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-371089e4e2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_train_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_TRAIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mXYpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_test_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_TEST\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=np.float64,\n\u001b[0;32m--> 465\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [56, 1]"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    Ypipeline, XYpipeline = retrieve_pipelines(\"ridge_model\", Ridge(alpha = 0.8))\n",
    "    this_y_train = Y_TRAIN.iloc[:,label]\n",
    "    this_y_test = Y_TEST.iloc[:,label]\n",
    "    \n",
    "    # TODO: Y contains all labels - need to subselect one based on label variable\n",
    "    y_train_tr = Ypipeline.fit_transform(this_y_train)\n",
    "    XYpipeline.fit(X_TRAIN,this_y_train)\n",
    "\n",
    "    y_test_tr = Ypipeline.transform(Y_TEST.iloc[:,label])\n",
    "    y_prediction = XYpipeline.predict(X_TEST)\n",
    "\n",
    "    y_prediction = Ypipeline.named_steps['standardizer'].inverse_transform(y_prediction)\n",
    "    y_prediction = imputer_inverse_transform(Y_TEST.iloc[:,label], y_prediction)\n",
    "\n",
    "    y_test_np = Y_TEST.iloc[:,label].copy().values.flatten()\n",
    "    y_test_np = y_test_np[~np.isnan(y_test_np)]\n",
    "    y_prediction = y_prediction[~np.isnan(y_prediction)]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_np, y_prediction))\n",
    "    r = scipy.stats.pearsonr(y_test_np, y_prediction)\n",
    "    t = scipy.stats.spearmanr(y_test_np, y_prediction)\n",
    "\n",
    "    print(\"RMSE: \" + str(rmse))\n",
    "    print(\"Pearson: \" + str(r))\n",
    "    print(\"Spearman: \" + str(t))\n",
    "\n",
    "    plt.plot(y_test_np, y_prediction, 'bo')\n",
    "    abline(1,0)\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "    scores = cross_val_score(XYpipeline, x_train, y_train_tr,\n",
    "                             scoring = \"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    scores = Ypipeline.named_steps['standardizer'].inverse_transform(scores)\n",
    "    \n",
    "    print(\"CV Scores: \" + str(scores))\n",
    "    print(\"CV Mean: \" + str(scores.mean()))\n",
    "    print(\"CV STD: \" + str(scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize ML results using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=15 must be between 0 and n_features=13 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-dc238b51730f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     ])\n\u001b[1;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mXYpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_labels_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\bbece\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    381\u001b[0m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[1;32m    382\u001b[0m                              \u001b[1;34m\"n_features=%r with svd_solver='full'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                              % (n_components, n_features))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[1;31m# Center data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=15 must be between 0 and n_features=13 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    #\n",
    "    # Select label column\n",
    "    #\n",
    "    selected_training_set = labeled_matrix_training_set.iloc[:, list([label]) + list(range(6,labeled_matrix_training_set.shape[1]))].copy()\n",
    "    selected_training_set = selected_training_set[~np.isnan(selected_training_set.iloc[:,0])]\n",
    "    #\n",
    "    # Divide into training set and testing set\n",
    "    #\n",
    "    training_set, testing_set = split_train_test(selected_training_set, test_ratio = 0.33) # TODO: Use sklearn's train_test_split\n",
    "\n",
    "    #\n",
    "    # Get model training information and preprocess\n",
    "    #\n",
    "    model_data = training_set.copy().drop([training_set.columns[0]], axis = 1)\n",
    "    model_labels = training_set.copy()[[training_set.columns[0]]]\n",
    "\n",
    "    Ypipeline = Pipeline([\n",
    "     ('imputer', Imputer(axis=0,strategy=\"median\")),\n",
    "     ('standardizer', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    model_labels_tr = Ypipeline.fit_transform(model_labels)\n",
    "\n",
    "    XYpipeline = Pipeline([\n",
    "            ('pca', decomposition.PCA(n_components=15)),\n",
    "            ('imputer', Imputer(axis=0,strategy=\"median\")),\n",
    "            ('standardizer', StandardScaler()),\n",
    "            ('rf_model', RandomForestRegressor(n_estimators=100, max_leaf_nodes=16, n_jobs=4)) # TODO: For now, hardcore the parameters\n",
    "    ])\n",
    "\n",
    "    XYpipeline.fit(model_data, model_labels_tr)\n",
    "\n",
    "    #\n",
    "    # TODO: To prevent data leakage, separate the scope after the model has been fit\n",
    "    #\n",
    "\n",
    "    #\n",
    "    # Get model testing information and preprocess\n",
    "    #\n",
    "    model_test_data = testing_set.copy().drop([testing_set.columns[0]], axis = 1)\n",
    "    model_test_labels = testing_set.copy()[[testing_set.columns[0]]]\n",
    "\n",
    "    model_test_labels_tr = Ypipeline.transform(model_test_labels)\n",
    "    predictions = XYpipeline.predict(model_test_data)\n",
    "\n",
    "    def imputer_inverse_transform(pre_data, post_data):\n",
    "        na_indices = np.where(np.isnan(pre_data))[0]\n",
    "        pprint(na_indices)\n",
    "        post_data[na_indices] = float('NaN')\n",
    "        return post_data\n",
    "\n",
    "\n",
    "    predictions = Ypipeline.named_steps['standardizer'].inverse_transform(predictions)\n",
    "    predictions = imputer_inverse_transform(model_test_labels, predictions)\n",
    "\n",
    "    model_test_labels = model_test_labels.copy().values.flatten()\n",
    "    model_test_labels = model_test_labels[~np.isnan(model_test_labels)]\n",
    "    predictions = predictions[~np.isnan(predictions)]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(model_test_labels, predictions))\n",
    "    r = scipy.stats.pearsonr(model_test_labels, predictions)\n",
    "    t = scipy.stats.spearmanr(model_test_labels, predictions)\n",
    "\n",
    "    print(\"RMSE: \" + str(rmse))\n",
    "    print(\"Pearson: \" + str(r))\n",
    "    print(\"Spearman: \" + str(t))\n",
    "\n",
    "    plt.plot(model_test_labels, predictions, 'bo')\n",
    "    abline(1,0)\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "    #scores = cross_val_score(XYpipeline, model_data, model_labels_tr,\n",
    "                             #scoring = \"neg_mean_squared_error\", cv=10)\n",
    "    #scores = Ypipeline.named_steps['standardizer'].inverse_transform(scores)\n",
    "    \n",
    "    #print(\"CV Scores: \" + str(scores))\n",
    "    #print(\"CV Mean: \" + str(scores.mean()))\n",
    "    #print(\"CV STD: \" + str(scores.std()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
